# 前言

很多人都可以Github上找到高级的AI代码；自己找到数据训练。例如：自动写诗
![对联](../img/深度学习/对联.png)

周星驰的电影里如果对穿肠有这样的机器，啧啧

上述图片来自[GPT2-Chinese](<https://github.com/Morizeyao/GPT2-Chinese>)；最近很火的[GPT3](<https://github.com/openai/gpt-3>)又出来的；据说很强大。

如果你不需要读懂源码，不需要更改算法模型，拿下来找到数据，训练自己的模型还是可以的。如果想要了解原理，并进行优化；则需要学习深度学习。学习深度学习的第一步是要知道什么是神经元。

# 什么是深度学习

`深度学习是一种实现机器学习的技术，机器学习是一种实现人工智能的方法。`

人工智能很多企业都在谈及并投入生产研究，这就导致了近几年什么专业的高材生都在扎堆这个领域。

机器学习，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。

深度学习：深度：包含多个隐含层的神经网络结构（就是深，即网络层数很多）；学习：实现机器学习的技术（前面看机器学习时干啥的）。

![深度学习与机器学习](../img/深度学习/深度学习和机器学习的关系.png)

# 什么是神经网络

![一个简单的神经网络](../img/深度学习/一个简单的神经网络.png)

x1,x2,x3 是输入层；第二层 是隐藏层；第三层是输出层

神经网络：就是N个上图的小圆圈组成的有输入中间层输出的网络

# 开启神经元

## MP模型诞生

1943年，基于生物神经网络莫克罗-彼特氏神经模型（McCulloch－Pitts′neuronmodel）诞生。它由心理学家Warren McCulloch和数学家Walter Pitts合作提出。

![MP](../img/深度学习/MP.png)

**神经元模型是一个包含输入，输出与计算功能的模型。**

输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。类比看一下生物的神经元如下：

![生物神经元](../img/深度学习/生物神经元.png)

McCulloch-Pitts模型公式:

![MP公式](../img/深度学习/mp公式.png)

抽象出神经元模型

![神经元模型](../img/深度学习/神经元模型.png)

z是在输入a和权值w的线性加权sum和叠加了一个函数g的值。在MP模型里，函数g是sgn函数，也就是取符号函数。这个函数当输入大于0时，输出1，否则输出0。

简单的MP模型，建立了神经网络大厦的地基。但是，MP模型中，权重的值都是预先设置的，因此不能学习。

1949年心理学家Hebb提出了Hebb学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。

## 单层神经网络-感知器

1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字--“**感知器**”（Perceptron）

![单层神经网络](../img/深度学习/单层神经网络.png)

与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个逻辑回归模型，可以做线性分类任务。

### 代码
```
# -*- coding: UTF-8 -*-
import numpy  as np
import matplotlib  as mpl
import matplotlib.pyplot as plt

#定义坐标,设定6组输入数据，每组为（x0,x1,x2）
X=np.array([[1,4,3],
            [1,5,4],
            [1,4,5],
            [1,1,1],
            [1,2,1],
            [1,3,2]]);

#设定输入向量的期待输出值
Y=np.array([1,1,1,-1,-1,-1]);

#设定权值向量(w0,w1,w2),权值范围为-1,1
W = (np.random.random(3)-0.5)*2;
#设定学习率
lr = 0.3;
#计算迭代次数
n=0;
#神经网络输出
O=0;

def  update():
    global  X,Y,W,lr,n;
    n=n+1;
    O=np.sign(np.dot(X,W.T));
    #计算权值差
    W_Tmp = lr*((Y-O.T).dot(X));
    W = W+W_Tmp;


if __name__ == '__main__':
    for index in range (100):
        update()

        O=np.sign(np.dot(X,W.T))
#         print(O)
#         print(Y)
        if(O == Y).all():
            print('Finished')
            print('epoch:',n)
            break
x1=[3,4]
y1=[3,3]
x2=[1]
y2=[1]

k=-W[1]/W[2]
d=-W[0]/W[2]
print('k=',k)
print('d=',d)
xdata=np.linspace(0,5)
plt.figure()
plt.plot(xdata,xdata*k+d,'r')
plt.plot(x1,y1,'bo')
plt.plot(x2,y2,'yo')
plt.show()
```


